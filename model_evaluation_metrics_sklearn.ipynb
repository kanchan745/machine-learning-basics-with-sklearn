{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgGQuMc5ygTmzBP0KWam42",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanchan745/machine-learning-basics-with-sklearn/blob/main/model_evaluation_metrics_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#classfication matrix\n",
        "learns to evaluate , classification models using accuracy ,precision ,  recall, and F1 score\n",
        "**formula**\n",
        "#accuracy = correct prediction / (divided by ) Total prediction\n",
        "#precision\n",
        "is  used when we ve to avoide false claim(6/10) = 60%\n",
        "#Recall\n",
        "actual positive cases in the model\n",
        "#F1 score\n",
        "precision and smart balance\n",
        "**used when data is imbalance**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hl1RPjRFpzxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion matrix :\n",
        "understand how to use a confusion matrix to analyze model performance"
      ],
      "metadata": {
        "id": "npXiGY8HqyKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regression Metrices\n",
        "learn to evaluate Regression using MAE , MSE and RMSE"
      ],
      "metadata": {
        "id": "XqyCMNL2rJKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sklearn Matrics\n",
        "Master the use of 'sklearn matrices' for comprehension model evaluation\n"
      ],
      "metadata": {
        "id": "jukvr2h8rbGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn matrics it is like toolbox\n",
        "# To check -model accuracy , how far your guesses were , how often ur model is wrong or right\n",
        "from sklearn.metrics import accuracy_score , precision_score , recall_score , f1_score #functions\n",
        "#True ans data\n",
        "y_true = [1,0,1,1,0,1,0]\n",
        "#Model's prediction -> what it guess\n",
        "y_pred = [1,0,1,0,0,1,1]\n",
        "#evaluate\n",
        "print (\"Accuracy : \", accuracy_score(y_true , y_pred))\n",
        "print (\"Precision : \", precision_score(y_true , y_pred))\n",
        "print (\"Recall : \", recall_score(y_true , y_pred))\n",
        "print(\"f1 score : \", f1_score(y_true , y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqKb7DtNrtZA",
        "outputId": "c6e120fe-52ef-4fd3-a1d4-ed2d0496de54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.7142857142857143\n",
            "Precision :  0.75\n",
            "Recall :  0.75\n",
            "f1 score :  0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Truepositive #Truenegative\n",
        "#confusion matrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_true = [1,0,1,1,0,1,0,0,1,0]\n",
        "y_pred = [1,0,1,0,0,1,1,0,1,0]\n",
        "cm = confusion_matrix(y_true , y_pred)\n",
        "print (\"Confusion Matrix\")\n",
        "print (cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZdEVr9zwSp1",
        "outputId": "3db10683-f54d-45a2-ea6f-6b1bb8c709fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[4 1]\n",
            " [1 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAE , MSE ,RMSE\n",
        "#MAE mean absolute error - on an average\n",
        "#1> take the mistake difference ,2> remove the minus sign ,3> add ,4>divide ,5>On average\n",
        "\n",
        "#MSE - Mean Squared error :- steps -1> Mistake Square them ,2> add ,3> divide total\n",
        "#RMSE - Root mean square Error - (how much wrong the prediction is )\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "import numpy as np\n",
        "#real score\n",
        "real_scores = [90,60,80,100]\n",
        "\n",
        "#model guess\n",
        "predicted_scores = [85,70,70,95]\n",
        "\n",
        "mae = mean_absolute_error(real_scores , predicted_scores)\n",
        "mse = mean_squared_error(real_scores , predicted_scores)\n",
        "rmse = np.sqrt(mse)\n",
        "print (\"MAE : On average off by  : \", mae)\n",
        "print (\"MSE Squared Mistake Value : \", mse)\n",
        "print (\"RMSE Final Realistic error : \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op63I4TcyJY9",
        "outputId": "ee5daf97-d048-4f83-a35f-8d4d6d12306b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE : On average off by  :  7.5\n",
            "MSE Squared Mistake Value :  62.5\n",
            "RMSE Final Realistic error :  7.905694150420948\n"
          ]
        }
      ]
    }
  ]
}